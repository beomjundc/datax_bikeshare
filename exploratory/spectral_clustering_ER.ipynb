{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the trip summary data\n",
    "file_path = '../data/trip_summary_201901.csv'\n",
    "trips = pd.read_csv(file_path)\n",
    "trips = trips.dropna(how=\"any\")\n",
    "\n",
    "trips['start_station_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_cap</th>\n",
       "      <th>start_station_has_kiosk</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_cap</th>\n",
       "      <th>end_station_has_kiosk</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>sum_duration_sec</th>\n",
       "      <th>sum_duration_min</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>subscriber_trip_count</th>\n",
       "      <th>customer_trip_count</th>\n",
       "      <th>station_pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>17th St at Valencia St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>141</td>\n",
       "      <td>Valencia St at Cesar Chavez St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>37.747998</td>\n",
       "      <td>-122.420219</td>\n",
       "      <td>390</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109_141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>17th St at Valencia St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>91</td>\n",
       "      <td>Berry St at King St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>37.771762</td>\n",
       "      <td>-122.398438</td>\n",
       "      <td>780</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91_109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>Esprit Park</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.759177</td>\n",
       "      <td>-122.436943</td>\n",
       "      <td>37.761634</td>\n",
       "      <td>-122.390648</td>\n",
       "      <td>1306</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118_126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>18th St at Noe St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>98</td>\n",
       "      <td>Valencia St at 16th St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.761047</td>\n",
       "      <td>-122.432642</td>\n",
       "      <td>37.765052</td>\n",
       "      <td>-122.421866</td>\n",
       "      <td>422</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98_119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>Mission Dolores Park</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>98</td>\n",
       "      <td>Valencia St at 16th St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.761420</td>\n",
       "      <td>-122.426435</td>\n",
       "      <td>37.765052</td>\n",
       "      <td>-122.421866</td>\n",
       "      <td>277</td>\n",
       "      <td>4.616667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98_120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date  start_hour  start_station_id               start_station_name  \\\n",
       "0  2019-01-01           0               109           17th St at Valencia St   \n",
       "1  2019-01-01           0               109           17th St at Valencia St   \n",
       "2  2019-01-01           0               118  Eureka Valley Recreation Center   \n",
       "3  2019-01-01           0               119                18th St at Noe St   \n",
       "4  2019-01-01           0               120             Mission Dolores Park   \n",
       "\n",
       "   start_station_cap start_station_has_kiosk  end_station_id  \\\n",
       "0               23.0                    True             141   \n",
       "1               23.0                    True              91   \n",
       "2               19.0                    True             126   \n",
       "3               15.0                    True              98   \n",
       "4               27.0                    True              98   \n",
       "\n",
       "                 end_station_name  end_station_cap end_station_has_kiosk  \\\n",
       "0  Valencia St at Cesar Chavez St             19.0                  True   \n",
       "1             Berry St at King St             23.0                  True   \n",
       "2                     Esprit Park             31.0                  True   \n",
       "3          Valencia St at 16th St             23.0                  True   \n",
       "4          Valencia St at 16th St             23.0                  True   \n",
       "\n",
       "   start_station_latitude  start_station_longitude  end_station_latitude  \\\n",
       "0               37.763316              -122.421904             37.747998   \n",
       "1               37.763316              -122.421904             37.771762   \n",
       "2               37.759177              -122.436943             37.761634   \n",
       "3               37.761047              -122.432642             37.765052   \n",
       "4               37.761420              -122.426435             37.765052   \n",
       "\n",
       "   end_station_longitude  sum_duration_sec  sum_duration_min  trip_count  \\\n",
       "0            -122.420219               390          6.500000           1   \n",
       "1            -122.398438               780         13.000000           1   \n",
       "2            -122.390648              1306         21.766667           1   \n",
       "3            -122.421866               422          7.033333           1   \n",
       "4            -122.421866               277          4.616667           1   \n",
       "\n",
       "   subscriber_trip_count  customer_trip_count station_pair_id  \n",
       "0                      1                    0         109_141  \n",
       "1                      1                    0          91_109  \n",
       "2                      1                    0         118_126  \n",
       "3                      1                    0          98_119  \n",
       "4                      1                    0          98_120  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create station pair identifiers and group the data\n",
    "\n",
    "# Function: sorts the pair array and concatenates them to create a unique ID\n",
    "def sort_concat(arr):\n",
    "    arr_sorted = np.sort(arr)\n",
    "    pair_id = str(arr_sorted[0]) + '_' + str(arr_sorted[1])\n",
    "    \n",
    "    return pair_id\n",
    "\n",
    "pair_id = trips[['start_station_id', 'end_station_id']].values\n",
    "pair_id_sorted = list(map(sort_concat, pair_id))\n",
    "\n",
    "trips['station_pair_id'] = pair_id_sorted\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   4   5   6   8   9  10  11  13  14  15  16  17  19  20  21  22  23\n",
      "  24  25  26  27  28  29  30  31  33  34  36  37  39  41  42  43  44  47\n",
      "  49  50  52  53  54  55  56  58  59  60  61  62  63  64  66  67  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  84  85  86  87  88  89  90  91\n",
      "  92  93  95  96  97  98  99 100 101 102 104 105 106 107 108 109 110 112\n",
      " 113 114 115 116 118 119 120 121 122 123 124 125 126 127 129 130 131 132\n",
      " 133 134 136 137 138 139 140 141 142 144 145 146 147 223 284 285 321 323\n",
      " 324 336 343 345 349 350 355 356 358 359 360 361 362 363 364 365 368 369\n",
      " 370 371 373 375 377 380 381 383] \n",
      "\n",
      "152 \n",
      "\n",
      "     station_pair_id  trip_count  sum_duration_min  station_i  station_j  \\\n",
      "5014           3_350          61        724.216667          3        350   \n",
      "5036            3_39          14        249.866667          3         39   \n",
      "5037             3_4          17        534.300000          3          4   \n",
      "5038            3_41          51        493.050000          3         41   \n",
      "5039            3_42          74        655.966667          3         42   \n",
      "\n",
      "      trip_count_inv  \n",
      "5014        0.016393  \n",
      "5036        0.071429  \n",
      "5037        0.058824  \n",
      "5038        0.019608  \n",
      "5039        0.013514   \n",
      "\n",
      "[[0.01639344 0.05882353 0.00943396 ... 0.1        1.         0.09090909]\n",
      " [0.05882353 0.2        0.03571429 ... 0.33333333 1.         0.14285714]\n",
      " [0.00943396 0.03571429 0.015625   ... 0.07142857 1.         0.11111111]\n",
      " ...\n",
      " [0.1        0.33333333 0.07142857 ... 0.0625     0.         1.        ]\n",
      " [1.         1.         1.         ... 0.         0.14285714 1.        ]\n",
      " [0.09090909 0.14285714 0.11111111 ... 1.         1.         1.        ]] \n",
      "\n",
      "(152, 152)\n"
     ]
    }
   ],
   "source": [
    "# Create an affinity matrix from the data\n",
    "pair_trips = trips.groupby('station_pair_id', as_index=False)['trip_count','sum_duration_min'].sum()\n",
    "pair_trips['station_i'] = pair_trips['station_pair_id'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "pair_trips['station_j'] = pair_trips['station_pair_id'].str.split(\"_\", n = 1, expand = True)[1]\n",
    "intercluster_volume = pair_trips\n",
    "pair_trips['trip_count_inv'] = 1 / pair_trips['trip_count']\n",
    "\n",
    "pair_trips['station_i'] = pd.to_numeric(pair_trips['station_i']).astype(np.int64)\n",
    "pair_trips['station_j'] = pd.to_numeric(pair_trips['station_j']).astype(np.int64)\n",
    "\n",
    "stations_sorted = pair_trips.sort_values(['station_i'])['station_i'].unique()\n",
    "pair_trips = pair_trips.sort_values(['station_i'])\n",
    "\n",
    "print(stations_sorted,\"\\n\")\n",
    "print(len(stations_sorted),\"\\n\")\n",
    "print(pair_trips.head(), \"\\n\")\n",
    "\n",
    "# Generate affinity matrix from pair_trips\n",
    "upp_mat = pair_trips.set_index(['station_i','station_j'])['trip_count_inv'].unstack().values\n",
    "\n",
    "aff_mat = np.triu(upp_mat) + np.triu(upp_mat, 1).T\n",
    "aff_mat[np.isnan(aff_mat)] = 0\n",
    "\n",
    "print(aff_mat, \"\\n\")\n",
    "print(aff_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94702883 0.82259411 0.96916493 ... 0.71748944 0.0361539  0.73947449]\n",
      " [0.82259411 0.5147911  0.88818931 ... 0.33066258 0.0361539  0.62233205]\n",
      " [0.96916493 0.88818931 0.94944798 ... 0.78888025 0.0361539  0.69150451]\n",
      " ...\n",
      " [0.71748944 0.33066258 0.78888025 ... 0.81261474 1.         0.0361539 ]\n",
      " [0.0361539  0.0361539  0.0361539  ... 1.         0.62233205 0.0361539 ]\n",
      " [0.73947449 0.62233205 0.69150451 ... 0.0361539  0.0361539  0.0361539 ]]\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# Spectral clustering on the affinity matrix\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "beta = 1\n",
    "sim_mat = np.exp(-beta * aff_mat / aff_mat.std(ddof=0))\n",
    "print(sim_mat)\n",
    "\n",
    "sc = SpectralClustering(3, affinity='precomputed', n_init=100, assign_labels='discretize')\n",
    "clusters = sc.fit_predict(sim_mat)\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 2, 2, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 0,\n",
       "       1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 0, 2, 2,\n",
       "       2, 2, 1, 1, 0, 1, 0, 0, 2, 2, 1, 1, 2, 1, 0, 2, 0, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 2, 2, 2, 1, 2, 0, 0, 1, 2, 0, 0, 0, 2, 2, 2, 2, 2, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 6),\n",
       " (4, 5),\n",
       " (5, 6),\n",
       " (6, 4),\n",
       " (8, 9),\n",
       " (9, 14),\n",
       " (10, 3),\n",
       " (11, 9),\n",
       " (13, 11),\n",
       " (14, 1),\n",
       " (15, 4),\n",
       " (16, 4),\n",
       " (17, 4),\n",
       " (19, 6),\n",
       " (20, 6),\n",
       " (21, 6),\n",
       " (22, 4),\n",
       " (23, 9),\n",
       " (24, 4),\n",
       " (25, 4),\n",
       " (26, 11),\n",
       " (27, 4),\n",
       " (28, 9),\n",
       " (29, 3),\n",
       " (30, 4),\n",
       " (31, 7),\n",
       " (33, 3),\n",
       " (34, 5),\n",
       " (36, 4),\n",
       " (37, 4),\n",
       " (39, 8),\n",
       " (41, 5),\n",
       " (42, 2),\n",
       " (43, 6),\n",
       " (44, 6),\n",
       " (47, 4),\n",
       " (49, 11),\n",
       " (50, 3),\n",
       " (52, 10),\n",
       " (53, 3),\n",
       " (54, 0),\n",
       " (55, 10),\n",
       " (56, 2),\n",
       " (58, 6),\n",
       " (59, 6),\n",
       " (60, 7),\n",
       " (61, 7),\n",
       " (62, 5),\n",
       " (63, 7),\n",
       " (64, 5),\n",
       " (66, 9),\n",
       " (67, 6),\n",
       " (70, 6),\n",
       " (71, 10),\n",
       " (72, 6),\n",
       " (73, 6),\n",
       " (74, 6),\n",
       " (75, 6),\n",
       " (76, 6),\n",
       " (77, 11),\n",
       " (78, 11),\n",
       " (79, 14),\n",
       " (80, 3),\n",
       " (81, 4),\n",
       " (84, 10),\n",
       " (85, 6),\n",
       " (86, 6),\n",
       " (87, 7),\n",
       " (88, 6),\n",
       " (89, 8),\n",
       " (90, 4),\n",
       " (91, 14),\n",
       " (92, 4),\n",
       " (93, 4),\n",
       " (95, 6),\n",
       " (96, 9),\n",
       " (97, 6),\n",
       " (98, 0),\n",
       " (99, 14),\n",
       " (100, 8),\n",
       " (101, 3),\n",
       " (102, 5),\n",
       " (104, 4),\n",
       " (105, 0),\n",
       " (106, 9),\n",
       " (107, 12),\n",
       " (108, 11),\n",
       " (109, 0),\n",
       " (110, 12),\n",
       " (112, 12),\n",
       " (113, 8),\n",
       " (114, 11),\n",
       " (115, 8),\n",
       " (116, 4),\n",
       " (118, 0),\n",
       " (119, 0),\n",
       " (120, 0),\n",
       " (121, 0),\n",
       " (122, 0),\n",
       " (123, 5),\n",
       " (124, 2),\n",
       " (125, 3),\n",
       " (126, 4),\n",
       " (127, 0),\n",
       " (129, 8),\n",
       " (130, 2),\n",
       " (131, 11),\n",
       " (132, 13),\n",
       " (133, 0),\n",
       " (134, 0),\n",
       " (136, 10),\n",
       " (137, 2),\n",
       " (138, 7),\n",
       " (139, 8),\n",
       " (140, 10),\n",
       " (141, 13),\n",
       " (142, 1),\n",
       " (144, 2),\n",
       " (145, 1),\n",
       " (146, 1),\n",
       " (147, 0),\n",
       " (223, 0),\n",
       " (284, 4),\n",
       " (285, 6),\n",
       " (321, 13),\n",
       " (323, 9),\n",
       " (324, 6),\n",
       " (336, 3),\n",
       " (343, 13),\n",
       " (345, 14),\n",
       " (349, 11),\n",
       " (350, 7),\n",
       " (355, 4),\n",
       " (356, 6),\n",
       " (358, 5),\n",
       " (359, 10),\n",
       " (360, 1),\n",
       " (361, 0),\n",
       " (362, 10),\n",
       " (363, 4),\n",
       " (364, 4),\n",
       " (365, 8),\n",
       " (368, 12),\n",
       " (369, 2),\n",
       " (370, 5),\n",
       " (371, 1),\n",
       " (373, 13),\n",
       " (375, 14),\n",
       " (377, 6),\n",
       " (380, 3),\n",
       " (381, 14),\n",
       " (383, 2)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(stations_sorted, clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance of spectral clustering on 1-15 clusters\n",
    "\n",
    "#### Output from this cell shows the mean volume and time for intercluster travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters    avg intercluster volume   avg intercluster time\n",
      "2           3.9095149253731343           61.31896075179676\n",
      "3           6.046330845771144           90.13701457987833\n",
      "4           8.06540215588723           110.51857207020448\n",
      "5           8.634535655058043           117.68637368711991\n",
      "6           8.90308872305141           122.7616172609175\n",
      "7           9.67858623548922           131.6637714206743\n",
      "8           10.329498341625207           137.59300027639583\n",
      "9           10.879145936981757           140.80326319789927\n",
      "10           11.387541459369817           150.22819755389702\n",
      "11           10.799025704809287           143.00603406578196\n",
      "12           10.73476368159204           141.93739289662795\n",
      "13           11.359970978441128           148.1271282476505\n",
      "14           12.297470978441128           158.27736491155335\n",
      "15           11.080949419568823           144.79847809563256\n"
     ]
    }
   ],
   "source": [
    "# Spectral clustering on the affinity matrix\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "print(\"clusters\",\"  \", \"avg intercluster volume\", \" \", \"avg intercluster time\")\n",
    "\n",
    "i = 2\n",
    "\n",
    "while i <= 15:\n",
    "\n",
    "    sc = SpectralClustering(i, affinity='precomputed', n_init=100, assign_labels='discretize')\n",
    "    clusters = sc.fit_predict(sim_mat)\n",
    "    \n",
    "    # select start station and trip count to new dataframe\n",
    "    intercluster_volume = intercluster_volume[['station_i','station_j', 'trip_count','sum_duration_min']]\n",
    "\n",
    "    #define a mapping dictionary\n",
    "    cluster_dict = dict(zip(stations_sorted, clusters))\n",
    "\n",
    "    # map the clusters to the starting stations\n",
    "    intercluster_volume['cluster_i'] = intercluster_volume['station_i'].map(cluster_dict)\n",
    "    intercluster_volume['cluster_j'] = intercluster_volume['station_j'].map(cluster_dict)\n",
    "\n",
    "\n",
    "    intercluster_volume.loc[intercluster_volume.cluster_i == intercluster_volume.cluster_j, 'intercluster_trip'] = 0 \n",
    "    intercluster_volume.loc[intercluster_volume.cluster_i != intercluster_volume.cluster_j, 'intercluster_trip'] = 1 \n",
    "\n",
    "    intercluster_volume['intercluster_volume'] = intercluster_volume['intercluster_trip']*intercluster_volume['trip_count']\n",
    "    intercluster_volume['intercluster_time_volume'] = intercluster_volume['intercluster_trip']*intercluster_volume['sum_duration_min']\n",
    "\n",
    "    print(i, \"         \", intercluster_volume['intercluster_volume'].mean(),\n",
    "          \"         \", intercluster_volume['intercluster_time_volume'].mean())\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>17th St at Valencia St</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>37.759177</td>\n",
       "      <td>-122.436943</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119</td>\n",
       "      <td>18th St at Noe St</td>\n",
       "      <td>37.761047</td>\n",
       "      <td>-122.432642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>Mission Dolores Park</td>\n",
       "      <td>37.761420</td>\n",
       "      <td>-122.426435</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>Mission Playground</td>\n",
       "      <td>37.759210</td>\n",
       "      <td>-122.421339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id                     station_name  station_latitude  \\\n",
       "0         109           17th St at Valencia St         37.763316   \n",
       "1         118  Eureka Valley Recreation Center         37.759177   \n",
       "2         119                18th St at Noe St         37.761047   \n",
       "3         120             Mission Dolores Park         37.761420   \n",
       "4         121               Mission Playground         37.759210   \n",
       "\n",
       "   station_longitude  cluster  \n",
       "0        -122.421904        2  \n",
       "1        -122.436943        6  \n",
       "2        -122.432642        2  \n",
       "3        -122.426435        2  \n",
       "4        -122.421339        2  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_clustered = list(zip(stations_sorted, clusters))\n",
    "df_station_clustered = pd.DataFrame(station_clustered)\n",
    "df_station_clustered.rename(columns={0:'station_id',\n",
    "                                    1: 'cluster'},inplace=True)\n",
    "\n",
    "start = trips[['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude']].drop_duplicates().rename(columns = {'start_station_id':'station_id', \\\n",
    "                                                 'start_station_name':'station_name', \\\n",
    "                                                 'start_station_latitude':'station_latitude', \n",
    "                                                 'start_station_longitude': 'station_longitude'})\n",
    "\n",
    "end = trips[['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude']].drop_duplicates().rename(columns = {'end_station_id':'station_id', \\\n",
    "                                             'end_station_name':'station_name', \\\n",
    "                                             'end_station_latitude':'station_latitude', \\\n",
    "                                             'end_station_longitude': 'station_longitude'})\n",
    "\n",
    "df_loc = pd.concat([start, end]).drop_duplicates()\n",
    "df_all = df_loc.merge(df_station_clustered, on=[\"station_id\"], how=\"right\")\n",
    "df_all.to_csv(\"df_station_clustered.csv\", index=None)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Code for single run of volume and time volume aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_i</th>\n",
       "      <th>station_j</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>sum_duration_min</th>\n",
       "      <th>cluster_i</th>\n",
       "      <th>cluster_j</th>\n",
       "      <th>intercluster_trip</th>\n",
       "      <th>intercluster_volume</th>\n",
       "      <th>intercluster_time_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>72.833333</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>7</td>\n",
       "      <td>18.816667</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>40.783333</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>106.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>54.516667</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.516667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_i  station_j  trip_count  sum_duration_min  cluster_i  cluster_j  \\\n",
       "0        100        100           8         72.833333          8          8   \n",
       "1        100        101           7         18.816667          8          3   \n",
       "2        100        102           9         40.783333          8          5   \n",
       "3        100        104          11        106.333333          8          4   \n",
       "4        100        105           6         54.516667          8          0   \n",
       "\n",
       "   intercluster_trip  intercluster_volume  intercluster_time_volume  \n",
       "0                0.0                  0.0                  0.000000  \n",
       "1                1.0                  7.0                 18.816667  \n",
       "2                1.0                  9.0                 40.783333  \n",
       "3                1.0                 11.0                106.333333  \n",
       "4                1.0                  6.0                 54.516667  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map clusters to roundtrip volume and rountrip volume time data\n",
    "\n",
    "# select start station and trip count to new dataframe\n",
    "intercluster_volume = intercluster_volume[['station_i','station_j', 'trip_count','sum_duration_min']]\n",
    "\n",
    "#define a mapping dictionary\n",
    "cluster_dict = dict(zip(stations_sorted, clusters))\n",
    "\n",
    "# map the clusters to the starting stations\n",
    "intercluster_volume['cluster_i'] = intercluster_volume['station_i'].map(cluster_dict)\n",
    "intercluster_volume['cluster_j'] = intercluster_volume['station_j'].map(cluster_dict)\n",
    "\n",
    "\n",
    "intercluster_volume.loc[intercluster_volume.cluster_i == intercluster_volume.cluster_j, 'intercluster_trip'] = 0 \n",
    "intercluster_volume.loc[intercluster_volume.cluster_i != intercluster_volume.cluster_j, 'intercluster_trip'] = 1 \n",
    "\n",
    "intercluster_volume['intercluster_volume'] = intercluster_volume['intercluster_trip']*intercluster_volume['trip_count']\n",
    "intercluster_volume['intercluster_time_volume'] = intercluster_volume['intercluster_trip']*intercluster_volume['sum_duration_min']\n",
    "\n",
    "intercluster_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
