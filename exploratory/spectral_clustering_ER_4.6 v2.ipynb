{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the trip summary data\n",
    "file_path = '../data/trip_summary_201901.csv'\n",
    "trips = pd.read_csv(file_path)\n",
    "trips = trips.dropna(how=\"any\")\n",
    "\n",
    "trips['start_station_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_cap</th>\n",
       "      <th>start_station_has_kiosk</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_cap</th>\n",
       "      <th>end_station_has_kiosk</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>sum_duration_sec</th>\n",
       "      <th>sum_duration_min</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>subscriber_trip_count</th>\n",
       "      <th>customer_trip_count</th>\n",
       "      <th>station_pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>17th St at Valencia St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>141</td>\n",
       "      <td>Valencia St at Cesar Chavez St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>37.747998</td>\n",
       "      <td>-122.420219</td>\n",
       "      <td>390</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109_141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>17th St at Valencia St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>91</td>\n",
       "      <td>Berry St at King St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>37.771762</td>\n",
       "      <td>-122.398438</td>\n",
       "      <td>780</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91_109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>Esprit Park</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.759177</td>\n",
       "      <td>-122.436943</td>\n",
       "      <td>37.761634</td>\n",
       "      <td>-122.390648</td>\n",
       "      <td>1306</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118_126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>18th St at Noe St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>98</td>\n",
       "      <td>Valencia St at 16th St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.761047</td>\n",
       "      <td>-122.432642</td>\n",
       "      <td>37.765052</td>\n",
       "      <td>-122.421866</td>\n",
       "      <td>422</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98_119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>Mission Dolores Park</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>98</td>\n",
       "      <td>Valencia St at 16th St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37.761420</td>\n",
       "      <td>-122.426435</td>\n",
       "      <td>37.765052</td>\n",
       "      <td>-122.421866</td>\n",
       "      <td>277</td>\n",
       "      <td>4.616667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98_120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date  start_hour  start_station_id               start_station_name  \\\n",
       "0  2019-01-01           0               109           17th St at Valencia St   \n",
       "1  2019-01-01           0               109           17th St at Valencia St   \n",
       "2  2019-01-01           0               118  Eureka Valley Recreation Center   \n",
       "3  2019-01-01           0               119                18th St at Noe St   \n",
       "4  2019-01-01           0               120             Mission Dolores Park   \n",
       "\n",
       "   start_station_cap start_station_has_kiosk  end_station_id  \\\n",
       "0               23.0                    True             141   \n",
       "1               23.0                    True              91   \n",
       "2               19.0                    True             126   \n",
       "3               15.0                    True              98   \n",
       "4               27.0                    True              98   \n",
       "\n",
       "                 end_station_name  end_station_cap end_station_has_kiosk  \\\n",
       "0  Valencia St at Cesar Chavez St             19.0                  True   \n",
       "1             Berry St at King St             23.0                  True   \n",
       "2                     Esprit Park             31.0                  True   \n",
       "3          Valencia St at 16th St             23.0                  True   \n",
       "4          Valencia St at 16th St             23.0                  True   \n",
       "\n",
       "   start_station_latitude  start_station_longitude  end_station_latitude  \\\n",
       "0               37.763316              -122.421904             37.747998   \n",
       "1               37.763316              -122.421904             37.771762   \n",
       "2               37.759177              -122.436943             37.761634   \n",
       "3               37.761047              -122.432642             37.765052   \n",
       "4               37.761420              -122.426435             37.765052   \n",
       "\n",
       "   end_station_longitude  sum_duration_sec  sum_duration_min  trip_count  \\\n",
       "0            -122.420219               390          6.500000           1   \n",
       "1            -122.398438               780         13.000000           1   \n",
       "2            -122.390648              1306         21.766667           1   \n",
       "3            -122.421866               422          7.033333           1   \n",
       "4            -122.421866               277          4.616667           1   \n",
       "\n",
       "   subscriber_trip_count  customer_trip_count station_pair_id  \n",
       "0                      1                    0         109_141  \n",
       "1                      1                    0          91_109  \n",
       "2                      1                    0         118_126  \n",
       "3                      1                    0          98_119  \n",
       "4                      1                    0          98_120  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create station pair identifiers and group the data\n",
    "\n",
    "# Function: sorts the pair array and concatenates them to create a unique ID\n",
    "def sort_concat(arr):\n",
    "    arr_sorted = np.sort(arr)\n",
    "    pair_id = str(arr_sorted[0]) + '_' + str(arr_sorted[1])\n",
    "    \n",
    "    return pair_id\n",
    "\n",
    "pair_id = trips[['start_station_id', 'end_station_id']].values\n",
    "pair_id_sorted = list(map(sort_concat, pair_id))\n",
    "\n",
    "trips['station_pair_id'] = pair_id_sorted\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   4   5   6   8   9  10  11  13  14  15  16  17  19  20  21  22  23\n",
      "  24  25  26  27  28  29  30  31  33  34  36  37  39  41  42  43  44  47\n",
      "  49  50  52  53  54  55  56  58  59  60  61  62  63  64  66  67  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  84  85  86  87  88  89  90  91\n",
      "  92  93  95  96  97  98  99 100 101 102 104 105 106 107 108 109 110 112\n",
      " 113 114 115 116 118 119 120 121 122 123 124 125 126 127 129 130 131 132\n",
      " 133 134 136 137 138 139 140 141 142 144 145 146 147 223 284 285 321 323\n",
      " 324 336 343 345 349 350 355 356 358 359 360 361 362 363 364 365 368 369\n",
      " 370 371 373 375 377 380 381 383] \n",
      "\n",
      "152 \n",
      "\n",
      "     station_pair_id  trip_count  station_i  station_j  trip_count_inv\n",
      "5014           3_350          61          3        350        0.016393\n",
      "5036            3_39          14          3         39        0.071429\n",
      "5037             3_4          17          3          4        0.058824\n",
      "5038            3_41          51          3         41        0.019608\n",
      "5039            3_42          74          3         42        0.013514 \n",
      "\n",
      "[[0.01639344 0.05882353 0.00943396 ... 0.1        1.         0.09090909]\n",
      " [0.05882353 0.2        0.03571429 ... 0.33333333 1.         0.14285714]\n",
      " [0.00943396 0.03571429 0.015625   ... 0.07142857 1.         0.11111111]\n",
      " ...\n",
      " [0.1        0.33333333 0.07142857 ... 0.0625     0.         1.        ]\n",
      " [1.         1.         1.         ... 0.         0.14285714 1.        ]\n",
      " [0.09090909 0.14285714 0.11111111 ... 1.         1.         1.        ]] \n",
      "\n",
      "(152, 152)\n"
     ]
    }
   ],
   "source": [
    "# Create an affinity matrix from the data\n",
    "pair_trips = trips.groupby('station_pair_id', as_index=False)['trip_count'].sum()\n",
    "pair_trips['station_i'] = pair_trips['station_pair_id'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "pair_trips['station_j'] = pair_trips['station_pair_id'].str.split(\"_\", n = 1, expand = True)[1]\n",
    "intercluster_volume = pair_trips\n",
    "pair_trips['trip_count_inv'] = 1 / pair_trips['trip_count']\n",
    "\n",
    "pair_trips['station_i'] = pd.to_numeric(pair_trips['station_i']).astype(np.int64)\n",
    "pair_trips['station_j'] = pd.to_numeric(pair_trips['station_j']).astype(np.int64)\n",
    "\n",
    "stations_sorted = pair_trips.sort_values(['station_i'])['station_i'].unique()\n",
    "pair_trips = pair_trips.sort_values(['station_i'])\n",
    "\n",
    "print(stations_sorted,\"\\n\")\n",
    "print(len(stations_sorted),\"\\n\")\n",
    "print(pair_trips.head(), \"\\n\")\n",
    "\n",
    "# Generate affinity matrix from pair_trips\n",
    "upp_mat = pair_trips.set_index(['station_i','station_j'])['trip_count_inv'].unstack().values\n",
    "\n",
    "aff_mat = np.triu(upp_mat) + np.triu(upp_mat, 1).T\n",
    "aff_mat[np.isnan(aff_mat)] = 0\n",
    "\n",
    "print(aff_mat, \"\\n\")\n",
    "print(aff_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94702883 0.82259411 0.96916493 ... 0.71748944 0.0361539  0.73947449]\n",
      " [0.82259411 0.5147911  0.88818931 ... 0.33066258 0.0361539  0.62233205]\n",
      " [0.96916493 0.88818931 0.94944798 ... 0.78888025 0.0361539  0.69150451]\n",
      " ...\n",
      " [0.71748944 0.33066258 0.78888025 ... 0.81261474 1.         0.0361539 ]\n",
      " [0.0361539  0.0361539  0.0361539  ... 1.         0.62233205 0.0361539 ]\n",
      " [0.73947449 0.62233205 0.69150451 ... 0.0361539  0.0361539  0.0361539 ]]\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# Spectral clustering on the affinity matrix\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "beta = 1\n",
    "sim_mat = np.exp(-beta * aff_mat / aff_mat.std(ddof=0))\n",
    "print(sim_mat)\n",
    "\n",
    "sc = SpectralClustering(3, affinity='precomputed', n_init=100, assign_labels='discretize')\n",
    "clusters = sc.fit_predict(sim_mat)\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 1,\n",
       "       2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 1, 0, 0,\n",
       "       0, 0, 2, 2, 1, 0, 1, 1, 0, 0, 2, 2, 0, 2, 1, 0, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2,\n",
       "       2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (8, 0),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 0),\n",
       " (30, 1),\n",
       " (31, 0),\n",
       " (33, 0),\n",
       " (34, 0),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (39, 2),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 0),\n",
       " (44, 1),\n",
       " (47, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (52, 0),\n",
       " (53, 0),\n",
       " (54, 0),\n",
       " (55, 0),\n",
       " (56, 2),\n",
       " (58, 1),\n",
       " (59, 2),\n",
       " (60, 1),\n",
       " (61, 1),\n",
       " (62, 1),\n",
       " (63, 0),\n",
       " (64, 1),\n",
       " (66, 1),\n",
       " (67, 1),\n",
       " (70, 0),\n",
       " (71, 0),\n",
       " (72, 0),\n",
       " (73, 0),\n",
       " (74, 0),\n",
       " (75, 0),\n",
       " (76, 0),\n",
       " (77, 2),\n",
       " (78, 0),\n",
       " (79, 1),\n",
       " (80, 2),\n",
       " (81, 1),\n",
       " (84, 0),\n",
       " (85, 0),\n",
       " (86, 0),\n",
       " (87, 0),\n",
       " (88, 2),\n",
       " (89, 2),\n",
       " (90, 1),\n",
       " (91, 0),\n",
       " (92, 1),\n",
       " (93, 1),\n",
       " (95, 0),\n",
       " (96, 0),\n",
       " (97, 2),\n",
       " (98, 2),\n",
       " (99, 0),\n",
       " (100, 2),\n",
       " (101, 1),\n",
       " (102, 0),\n",
       " (104, 2),\n",
       " (105, 0),\n",
       " (106, 2),\n",
       " (107, 2),\n",
       " (108, 2),\n",
       " (109, 2),\n",
       " (110, 2),\n",
       " (112, 2),\n",
       " (113, 2),\n",
       " (114, 2),\n",
       " (115, 2),\n",
       " (116, 2),\n",
       " (118, 0),\n",
       " (119, 2),\n",
       " (120, 0),\n",
       " (121, 2),\n",
       " (122, 2),\n",
       " (123, 0),\n",
       " (124, 2),\n",
       " (125, 2),\n",
       " (126, 1),\n",
       " (127, 2),\n",
       " (129, 2),\n",
       " (130, 2),\n",
       " (131, 1),\n",
       " (132, 0),\n",
       " (133, 2),\n",
       " (134, 2),\n",
       " (136, 2),\n",
       " (137, 0),\n",
       " (138, 0),\n",
       " (139, 2),\n",
       " (140, 0),\n",
       " (141, 2),\n",
       " (142, 0),\n",
       " (144, 2),\n",
       " (145, 0),\n",
       " (146, 2),\n",
       " (147, 0),\n",
       " (223, 2),\n",
       " (284, 1),\n",
       " (285, 0),\n",
       " (321, 1),\n",
       " (323, 1),\n",
       " (324, 1),\n",
       " (336, 2),\n",
       " (343, 1),\n",
       " (345, 1),\n",
       " (349, 1),\n",
       " (350, 1),\n",
       " (355, 2),\n",
       " (356, 0),\n",
       " (358, 0),\n",
       " (359, 0),\n",
       " (360, 0),\n",
       " (361, 0),\n",
       " (362, 0),\n",
       " (363, 1),\n",
       " (364, 1),\n",
       " (365, 2),\n",
       " (368, 0),\n",
       " (369, 1),\n",
       " (370, 1),\n",
       " (371, 1),\n",
       " (373, 0),\n",
       " (375, 0),\n",
       " (377, 0),\n",
       " (380, 0),\n",
       " (381, 0),\n",
       " (383, 2)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(stations_sorted, clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_pair_id</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>station_i</th>\n",
       "      <th>station_j</th>\n",
       "      <th>trip_count_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_100</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_101</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_102</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_104</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100_105</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_pair_id  trip_count  station_i  station_j  trip_count_inv\n",
       "0         100_100           8        100        100        0.125000\n",
       "1         100_101           7        100        101        0.142857\n",
       "2         100_102           9        100        102        0.111111\n",
       "3         100_104          11        100        104        0.090909\n",
       "4         100_105           6        100        105        0.166667"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercluster_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_i</th>\n",
       "      <th>station_j</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>cluster_i</th>\n",
       "      <th>cluster_j</th>\n",
       "      <th>intercluster_trip</th>\n",
       "      <th>intercluster_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_i  station_j  trip_count  cluster_i  cluster_j  intercluster_trip  \\\n",
       "0        100        100           8          2          2                0.0   \n",
       "1        100        101           7          2          1                1.0   \n",
       "2        100        102           9          2          0                1.0   \n",
       "3        100        104          11          2          2                0.0   \n",
       "4        100        105           6          2          0                1.0   \n",
       "\n",
       "   intercluster_volume  \n",
       "0                  0.0  \n",
       "1                  7.0  \n",
       "2                  9.0  \n",
       "3                  0.0  \n",
       "4                  6.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map clusters to roundtrip volume data\n",
    "\n",
    "# select start station and trip count to new dataframe\n",
    "intercluster_volume = intercluster_volume[['station_i','station_j', 'trip_count']]\n",
    "\n",
    "#define a mapping dictionary\n",
    "cluster_dict = dict(zip(stations_sorted, clusters))\n",
    "\n",
    "# map the clusters to the starting stations\n",
    "intercluster_volume['cluster_i'] = intercluster_volume['station_i'].map(cluster_dict)\n",
    "intercluster_volume['cluster_j'] = intercluster_volume['station_j'].map(cluster_dict)\n",
    "\n",
    "\n",
    "intercluster_volume.loc[intercluster_volume.cluster_i == intercluster_volume.cluster_j, 'intercluster_trip'] = 0 \n",
    "intercluster_volume.loc[intercluster_volume.cluster_i != intercluster_volume.cluster_j, 'intercluster_trip'] = 1 \n",
    "\n",
    "intercluster_volume['intercluster_volume'] = intercluster_volume['intercluster_trip']*intercluster_volume['trip_count']\n",
    "\n",
    "intercluster_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58104.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercluster_volume['intercluster_volume'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37719.0\n",
      "58104.0\n",
      "73586.0\n",
      "78853.0\n",
      "81138.0\n",
      "90381.0\n",
      "101995.0\n",
      "102385.0\n",
      "110834.0\n"
     ]
    }
   ],
   "source": [
    "# Spectral clustering on the affinity matrix\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "i = 2\n",
    "\n",
    "while i <= 10:\n",
    "\n",
    "    sc = SpectralClustering(i, affinity='precomputed', n_init=100, assign_labels='discretize')\n",
    "    clusters = sc.fit_predict(sim_mat)\n",
    "    \n",
    "    # select start station and trip count to new dataframe\n",
    "    intercluster_volume = intercluster_volume[['station_i','station_j', 'trip_count']]\n",
    "\n",
    "    #define a mapping dictionary\n",
    "    cluster_dict = dict(zip(stations_sorted, clusters))\n",
    "\n",
    "    # map the clusters to the starting stations\n",
    "    intercluster_volume['cluster_i'] = intercluster_volume['station_i'].map(cluster_dict)\n",
    "    intercluster_volume['cluster_j'] = intercluster_volume['station_j'].map(cluster_dict)\n",
    "\n",
    "\n",
    "    intercluster_volume.loc[intercluster_volume.cluster_i == intercluster_volume.cluster_j, 'intercluster_trip'] = 0 \n",
    "    intercluster_volume.loc[intercluster_volume.cluster_i != intercluster_volume.cluster_j, 'intercluster_trip'] = 1 \n",
    "\n",
    "    intercluster_volume['intercluster_volume'] = intercluster_volume['intercluster_trip']*intercluster_volume['trip_count']\n",
    "\n",
    "    print(intercluster_volume['intercluster_volume'].sum())\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>17th St at Valencia St</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>37.759177</td>\n",
       "      <td>-122.436943</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119</td>\n",
       "      <td>18th St at Noe St</td>\n",
       "      <td>37.761047</td>\n",
       "      <td>-122.432642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>Mission Dolores Park</td>\n",
       "      <td>37.761420</td>\n",
       "      <td>-122.426435</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>Mission Playground</td>\n",
       "      <td>37.759210</td>\n",
       "      <td>-122.421339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id                     station_name  station_latitude  \\\n",
       "0         109           17th St at Valencia St         37.763316   \n",
       "1         118  Eureka Valley Recreation Center         37.759177   \n",
       "2         119                18th St at Noe St         37.761047   \n",
       "3         120             Mission Dolores Park         37.761420   \n",
       "4         121               Mission Playground         37.759210   \n",
       "\n",
       "   station_longitude  cluster  \n",
       "0        -122.421904        2  \n",
       "1        -122.436943        6  \n",
       "2        -122.432642        2  \n",
       "3        -122.426435        2  \n",
       "4        -122.421339        2  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_clustered = list(zip(stations_sorted, clusters))\n",
    "df_station_clustered = pd.DataFrame(station_clustered)\n",
    "df_station_clustered.rename(columns={0:'station_id',\n",
    "                                    1: 'cluster'},inplace=True)\n",
    "\n",
    "start = trips[['start_station_id', 'start_station_name', 'start_station_latitude', 'start_station_longitude']].drop_duplicates().rename(columns = {'start_station_id':'station_id', \\\n",
    "                                                 'start_station_name':'station_name', \\\n",
    "                                                 'start_station_latitude':'station_latitude', \n",
    "                                                 'start_station_longitude': 'station_longitude'})\n",
    "\n",
    "end = trips[['end_station_id', 'end_station_name', 'end_station_latitude', 'end_station_longitude']].drop_duplicates().rename(columns = {'end_station_id':'station_id', \\\n",
    "                                             'end_station_name':'station_name', \\\n",
    "                                             'end_station_latitude':'station_latitude', \\\n",
    "                                             'end_station_longitude': 'station_longitude'})\n",
    "\n",
    "df_loc = pd.concat([start, end]).drop_duplicates()\n",
    "df_all = df_loc.merge(df_station_clustered, on=[\"station_id\"], how=\"right\")\n",
    "df_all.to_csv(\"df_station_clustered.csv\", index=None)\n",
    "df_all.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
